<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[TCP拥塞控制]]></title>
    <url>%2F2019%2F07%2F05%2FTCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[MSS: Maximum Segment Size 最大报文段长度 TCP拥塞控制算法 TCP拥塞控制算法包括慢启动、拥塞避免、快速恢复三个部分。 慢启动 TCP连接开始时，cwnd的值通常初始置为一个MSS的较小值，这就使得初始发送速率大约为 MSS/RTT；之后，每收到一个报文段的首次被确认cwnd就增加一个MSS。这样，第一个RTT中，cwnd为1 MSS， 第二个RTT中，cwnd为2 MSS， 第三个RTT中，cwnd为4 MSS， 即每个RTT之后，cwnd就翻倍，cwnd呈指数增长。 当发生丢包时，设置一个变量 ssthresh（慢启动阈值） = cwnd / 2, 然后cwnd重新设为1。 拥塞避免 当出现丢包时，如果（可能会直接进入快速恢复）进入慢启动阶段，ssthresh设为 cwnd/2, cwnd值置为1，然后每个RTT cwnd翻倍，当cwnd值到达 ssthresh之后，进入拥塞避免阶段。 此时，每个RTT，cwnd值只增加1个MSS，即每收到一个报文的ACK，cwnd = cwnd + MSS/cwnd.直到再次出现丢包后。当出现超时类型的丢包时，进入慢启动阶段（ssthresh = cwnd/2, cwnd=1）；当出现三次冗余ACK（参考TCP快速重传机制）类型的丢包时，进入快速恢复阶段（ssthresh = cwnd/2, cwnd = ssthreash + 3MSS) 快速恢复 当出现三次冗余ACK类型的丢包时，进入快速恢复阶段。此时 ssthresh = cwnd/2, cwnd = ssthreash + 3MSS，之后每个RTT内，cwnd增加1个MSS，直到出现丢包]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DASH内容生成]]></title>
    <url>%2F2019%2F07%2F03%2FDASH%E5%86%85%E5%AE%B9%E7%94%9F%E6%88%90%2F</url>
    <content type="text"><![CDATA[示例中big_buck_bunny的不同分辨率设置 https://dash.akamaized.net/akamai/bbb_30fps/bbb_30fps.mpd 254 kbps 320x180507 kbps 320x180759 kbps 480x2701013 kbps 640x3601254 kbps 640x3601883 kbps 768x4323134 kbps 1024x5764952 kbps 1280x7209914 kbps 1920x108014931 kbps 3840x2160 centos服务器安装ffmpeghttps://linuxize.com/post/how-to-install-ffmpeg-on-centos-7/centos服务器安装gpac1sudo yum install gpac 转码1ffmpeg -i big_buck_bunny_1080p_stereo.avi -s 3840x2160 -c:v libx264 -b:v 15000k -g 24 -an big_buck_bunny_3840x2160_15000k.mp4 切片到dash windows下1mp4box -dash 2000 -frag 2000 -rap -frag-rap -profile dashavc264:live -segment-name Video\$RepresentationID\$\segment -mpd-title Joker -out manifest.mpd big_buck_bunny_320x180_250k.mp4 big_buck_bunny_320x180_500k.mp4 big_buck_bunny_480x270_750k.mp4 big_buck_bunny_640x360_1000k.mp4 big_buck_bunny_640x360_1250k.mp4 big_buck_bunny_768x432_2000k.mp4 big_buck_bunny_1024x576_3000k.mp4 big_buck_bunny_1280x720_5000k.mp4 big_buck_bunny_1920x1080_10000k.mp4 big_buck_bunny_3840x2160_15000k.mp4 release_11mp4box -dash 2000 -frag 2000 -rap -frag-rap -profile dashavc264:live -segment-name Video$RepresentationID$\segment -mpd-title Joker -out manifest.mpd big_buck_bunny_320x180_250k.mp4 big_buck_bunny_320x180_500k.mp4 big_buck_bunny_480x270_750k.mp4 big_buck_bunny_640x360_1000k.mp4 big_buck_bunny_640x360_1250k.mp4 big_buck_bunny_768x432_1600k.mp4 big_buck_bunny_768x432_2000k.mp4 big_buck_bunny_1024x576_2500k.mp4 big_buck_bunny_1024x576_3000k.mp4 big_buck_bunny_1280x720_3500k.mp4 centos下：(不能用 原因是centos中gpac版本低，RepresentationID是视频名，与最新版本不同)1MP4Box -dash 2000 -frag 2000 -rap -frag-rap -profile dashavc264:live -segment-name Video\$RepresentationID\$/segment -mpd-title Joker -out manifest.mpd big_buck_bunny_320x180_250k.mp4 big_buck_bunny_320x180_500k.mp4 big_buck_bunny_480x270_750k.mp4 big_buck_bunny_640x360_1000k.mp4 big_buck_bunny_640x360_1250k.mp4 big_buck_bunny_768x432_2000k.mp4 big_buck_bunny_1024x576_3000k.mp4 big_buck_bunny_1280x720_5000k.mp4 big_buck_bunny_1920x1080_10000k.mp4 big_buck_bunny_3840x2160_15000k.mp4 dash player链接https://get-up.cn/dash_server/dash.js/samples/dash-if-reference-player/ big_buck_bunny mpd文件链接https://get-up.cn/dash_video/gop=24/manifest.mpdhttps://get-up.cn/dash_video/release_1/manifest.mpd RTT trace1ping -i 0.2 bilibili.com -D -c 1800000 &gt;ping_bilibili.log 37ms1ping -i 0.2 iqiyi.com -D -c 1800000 &gt;ping_iqiyi.log 26ms1ping -i 0.2 youku.com -D -c 1800000 &gt;ping_youku.log 30ms1ping -i 0.2 v.qq.com -D -c 1800000 &gt;ping_tencent.log 40ms1ping -i 0.2 ieeexplore.ieee.org -D -c 1800000 &gt;ping_ieee.log 220ms1ping -i 0.2 zhihu.com -D -c 1800000 &gt;ping_zhihu.log 12ms1ping -i 0.2 nus.edu.sg -D -c 1800000 &gt;ping_sg.log 300ms1ping -i 0.2 www.mtv.com.tw -D -c 1800000 &gt;ping_twmusic.log 80ms1ping -i 0.2 www.sonymusic.co.jp -D -c 1800000 &gt;ping_sonyjp.log 100ms 1ping -i 0.2 zhihu.com -D -c 1800000 &gt;ping_zhihu.log 12ms1ping -i 0.2 iqiyi.com -D -c 1800000 &gt;ping_iqiyi.log 26ms1ping -i 0.2 v.qq.com -D -c 1800000 &gt;ping_tencent.log 40ms1ping -i 0.2 www.mtv.com.tw -D -c 1800000 &gt;ping_twmusic.log 80ms1ping -i 0.2 www.sonymusic.co.jp -D -c 1800000 &gt;ping_sonyjp.log 100ms1ping -i 0.2 ieeexplore.ieee.org -D -c 1800000 &gt;ping_ieee.log 220ms1ping -i 0.2 nus.edu.sg -D -c 1800000 &gt;ping_sg.log 300ms1ping -i 0.2 bilibili.com -D -c 1800000 &gt;ping_bilibili.log 37ms wsl下文件目录1cd /mnt/d/My_Files/研一下/视频_多路径_RL/DataSet/Ping_Dataset linux下tcp抓包1tcpdump tcp and host 223.104.34.17 -w /home/wwwroot/default/tcpdump_data/dash_LTE.cap Linux其他命令将一个名为abc.txt的文件重命名为1234.txt1[root@station90 root]#mv abc.txt 1234.txt 更新wsl1sudo apt update &amp;&amp; sudo apt upgrade 更换中科大源编辑/etc/apt/sources.list文件, 在文件最前面添加以下条目(操作前请做好相应备份)：备份1sudo cp /etc/apt/sources.list /etc/apt/sources_init.list 更换源1sudo gedit /etc/apt/sources.list sources.list添加内容123456789101112##中科大源deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse 腾讯云主机tcp报文大于MTU值原因，同时也是为什么中断ACK一般报文的原因 Probably you captured on the host that transmitted the oversized packet, and TCP Large Segment Offload is enabled. (Sometimes abbreviated TSO and sometimes LSO.) The operating system is passing packets larger than MTU to the network adapter, and the network adapter driver is breaking them up so that they fit within the MTU. If you capture from the wire, instead of from an endpoint involved in the communication, you will see that the packets are correctly sized when they are transmitted. This is one reason of several to capture from the wire, instead of on an endpoint. 可能是您在传输超大数据包的主机上捕获，并启用了TCP大段卸载。 （有时缩写为TSO，有时缩写为LSO。）操作系统将大于MTU的数据包传递给网络适配器，网络适配器驱动程序将它们分解，以便它们适合MTU。 如果从线路捕获，而不是从通信中涉及的端点捕获，您将看到数据包在传输时的大小正确。 这是几个从线路捕获而不是在端点上捕获的原因之一。 Enable or Disable TSO on a Linux Virtual Machine123ethtool -K ethY tso onethtool -K ethY tso off 时间同步服务器设置win 10 解决办法 centos1ntpdate ntp.sjtu.edu.cn &amp;&amp; hwclock -w hwclock -w命令是将系统时间，写入BOIS 如果出现the NTP socketis in use, exiting解决办法12service ntp stopntpdate ntp.sjtu.edu.cn &amp;&amp; hwclock -w]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>DASH</tag>
        <tag>ffmpeg</tag>
        <tag>mp4box</tag>
        <tag>gpac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多路径传输中是视频传输和强化学习算法调研 + Research Proposal]]></title>
    <url>%2F2019%2F06%2F26%2F%E5%A4%9A%E8%B7%AF%E5%BE%84%E4%BC%A0%E8%BE%93%E4%B8%AD%E6%98%AF%E8%A7%86%E9%A2%91%E4%BC%A0%E8%BE%93%E5%92%8C%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E8%B0%83%E7%A0%94-Research-Proposal%2F</url>
    <content type="text"><![CDATA[多路径传输中是视频传输和强化学习算法调研 + Research ProposalVideo Streaming and MultipathCross-Layer Scheduler for Video Streaming Our objective is to increase the quality of experience (QoE) of the viewers by maximizing the reception of decodable video data in difficult conditions (video bit-rate close to the available bandwidth and small application buffer). Problem Description most transport protocols, including TCP, MPTCP and UDP, work at the bit-stream level and are not aware of the structure of the transported data Particularly, data are transmitted from the MPTCP Sending Buffer in the same order as they arrived to this buffer, even if some data should no longer be sent, for example an obsolete video unit whose playback deadline has already expired. Such an event is likely to occur in transport protocols that guarantee in-order delivery, such as TCP and MPTCP because the loss of one data packet can delay the delivery of multiple following packets. 普通的视频传输只会用ACK确认是否有到达，而不会标记和回传packet到达时间。回传到达时间可以让server在用户playback时估计用户可以在缓存中读取数据还是需要重新传输数据。 Passing Information between the Different Layers Video content awareness The cross-layer layer knows all those dependencies and so is able to infer whether the client can decode a video unit at a specific time or not. Each video unit is associated with a specific video frame (even for tiles) Network awareness The cross-layer scheduler knows the status of the network, including the smoothed Round-Trip Time (sRTT), the global moving average bandwidth and the loss probability of each path With the sRTT, the cross-layer scheduler can estimate the arrival time of each packets, and choose to send a video unit close to its deadline on the path with the shortest sRTT. From the moving average bandwidth, the scheduler can choose to drop some less important video units to favor others. From the loss probability, it can choose to send highly important video units on the path with the smallest loss probability the cross-layer scheduler needs to implement a feedback loop from the MPTCP socket. Although such feedback does not exist in open-source implementations yet, the development is not challenging since the server hosts both the MPTCP implementation and the application. Application awareness The cross-layer scheduler knows the status of the video player on the client. It can estimate the lag at the client side. From the lag, the start timestamp and the POC, the cross-layer scheduler can estimate the deadline of each video unit. The client can add extra information in its HTTP requests or use Real-Time Transport Control Protocol (RTCP) to implement this feedback in practice. The lag is a fixed value, which can be communicated to the server. The hardest thing is to estimate the timestamp when the client starts playing the decoded video. Algorithm The goal of our algorithm is to prioritize the video units that are the most likely to be received in time The crosslayer scheduler is content-aware (it knows how to extract video units) and application-aware (it is able to estimate their playback deadline from an applicative feedback loop). It is also network-aware (it knows which path the MPTCP stack selects to send the next packet as well as the sRTT of this path) Multipath and DRL (INFOCOM 2019, Nanjing University)Path select The reinforcement learning algorithm gets the information of every path and adaptively choose the most suitable path by the artificial intelligence. introduce DQN framework to enhance the MPTCP data scheduling performance in the asymmetric path assume the data scheduling problem and the path selection problem can be formulated as a MDP problem which can be calculated as the reinforcement learning problem. RL Model we use the sending window as the state of agent and the path as the action, so the value function is based on the sending window, the reward and the action. The aim is to optimize path selection to improve the transmission efficiency, and the model needs the information of state, action, and reward to make the decision We define the reward and punishment to impact to path selection. First, if we receive the acknowledgement of successful transmission from the chosen path, there will be a positive 1 reward for this path, but if we can not receive the acknowledgement, no matter the acknowledgement is lost or the data transmission is not finished in deadline, we will punish this path by getting the reward as -1. what is more, if the path is not available now, it will also get the punishment Evaluation The simulation is build on the famous Network Simulator version 3(NS3) with the newly added MPTCP module [13] the simulation is established under the heterogeneous condition to simulate asymmetrical networks. Multipath Data Scheduler A scheduler is responsible for determining the amount of data packets to be distributed onto the subflows, which has a significant impact on the performance of MPTCP Problem Description A typical value of SI (scheduling intervals) is 200ms, which is about 3∼4 RTTs The scheduler’s goal is to find the best set of split ratios (p1, p2, ··· , pn) for the subflows that lead to the optimal performance Solution Framework Online scheduling Offline training The online scheduling and offline training process run asynchronously and iteratively. After each episode the trainer synchronizes the scheduler with the trained neural network in adaption to the environment changes, driving the scheduling policy towards the optimum Reward Function :$R\left(s_{t}, a_{t}\right)=V_{t}^{\text { throughput }}-\alpha V_{t}^{\mathrm{RTT}}-\beta V_{t}^{\text { lost }}$ System Design At the sender, the chunk data coming from the application (APP) is stored in the meta buffer, and is then fetched, split, scheduled, and transmitted by the MPTCP scheduler. The policy network generates actions that determine the split ratio of each subflow for packet scheduling. The network states, actions, and rewards in each SI are passed to the collector and stored in a replay buffer, which will be used by the trainer to train the reinforcement learning model and update the policy network Receiver passively receives or acknowledges the data, reassembles it in the receiver-side meta buffer, and delivers the in-order data to the APP. In the implementation of the system, it requires interaction between the kernel and userspace Evaluation We implement ReLeS in the Linux kernel base on MPTCP v0.92 and evaluate it over both emulated and real network conditions. For emulation, we use Linux tc to throttle the bandwidth and to add extra delay on the sender. We consider different downloading files sizes varying from 64KB to 256MB to test the performance of the schedulers under different traffic classes. Tests under real-world settings (five locations) office, library, supermarket, dormitory and canteen Google Nexus 5 smartphone - Android 4.4, based on MPTCP v0.86.x My Research ProposalBackgroud Video streaming is the major source of traffic in mobile network.Currently, video content accounts for 50% of the cellular traffic and it is expected to account for around 75% of the mobile data traffic by the year of 2023 [1] It is common that today’s client hosts are equipped with multiple network interfaces. For example, mobile devices inherently support WiFi and cellular networks at the same time. In particular, HTTP-based ABR protocols dominate today’s landscape of video streaming over the Internet, and operate using multiple quality levels that are requested by video players one segment at a time. Most video websites adopt DASH, like YouTube, Netflix and bilibili. In wireless networks, it is well-known that variability in network bandwidth affects video streaming. 移动终端视频流量日益显著增加+移动终端均双网卡+现有的主流视频网站采用DASH try to improve mobile users’ QoE for DASH video streaming by multipath TCP Problem Description DASH needs to select one out of the L versions based on its estimation of the network condition and the buffer capacity. (YouTube: 144p, 240p, 360p, 480p,720p, 1080p, 3GPP Relaese 10已经将DASH纳入其中) DASH To play the content, the DASH client first obtains the MPD. The MPD can be delivered using HTTP MPD ：媒体文件的描述文件 客户端首先请求视频的MPD文件后解析获得视频包含的版本信息，客户端根据测试的带宽信息决定请求不同码率的视频。即不同的Representation，之后序列传输该视频码率(Representataion)下的媒体文件(Segment)。 初始的mp4文件，相当于视频头，在这个头文件中包含了完整的视频元信息(moov)。很小的一个文件，基本在1KB左右 上面提到的Segments文件，每个m4s仅包含媒体信息 (moof + mdat)，而播放器是不能直接播放这个文件的，需要用支持DASH的播放器从init文件开始播放。 最初想根据Initialization Segment与其他媒体Segment重要性不同区别对待，但当抓包后发现Initialization Segment只有1KB后这个想法就被抛弃了。 Problem 主流的视频网站都采用DASH作为视频流的播放解决方案，作为我们的视频端到端传输背景 现有的多路径数据调度算法 MinRTT, the default scheduler of MPTCP, attempts to fill the congestion window of the subflow with the lowest RTT before advancing to other subflows。总是优先利用带宽高的 The ReMP scheduler duplicates packets over all subflows in exchange for reliability。冗余传输提高可靠性 BLEST [13], a blocking estimation based scheduler, which takes a proactive stand towards minimising HoL-blocking The DEMS scheduler [14] aims at reducing the data chunk download time over multiple paths, whose benefits are maximized when the file size is small or medium 现有的Multipath packet调度算法在视频应用中没有考虑视频的特性，对于视频的端到端传输需要改进 视频包有前后的时间顺序，且后边依赖前边 视频包的重要性与play deadline 有关，距离播放时间越接近该包传输越急迫 当有包传输失败，重传该包时该包较正常传输包更重要 视频的流量很大，移动终端用户会考虑资费的问题从而对WiFi传输链路更加偏好故需要针对Video Streaming设计packet 调度算法 reward中考虑了用户观看视频QoE和WiFi的偏好 考虑cross-layer的调度，包括application layer码率的选择和transport layer包的调度。 这两个调度并非独立，码率的选择不当会使传输层丢包数增加，重传增加进一步增加网络开销，降低带宽； 包调度的不当会使得应用错误估计网络状况而选择传输低码率的视频，降低user-perceived QoE 合适的决策(码率选择+包调度)能有效地利用多路传输的优势提升视频质量到以前单路径传输所达不到的水平 为什么使用学习？ 网络的异构性，非对称网络，差别较大 WiFi和LTE网络均是Wireless Network，网络波动较大 参数较多，且优化目标考虑综合指标(comprehensive goals) Framework State cnwd of each path bandwidth measurement of each path mean RTT of each path sender buffer level player buffer level 当前待传输包与player当前播放内容时间的距离 Action 分辨率(Representation)选择(3~6个选择) packet 选择路径传输(两个选择) Reward $\alpha f_1(视频码率)+\beta f_2(码率切换次数)+ \gamma f_3(播放失败次数)+ \delta f_4\left(\frac{WiFi传输数据量}{LTE传输数据量} \quad \right) $ Policy Network 在服务器端运行 这个框架与现有的DASH有一个很大的不同是:现在通用的DASH是客户端而非服务器端来根据网络状况请求不同码率的视频，而该框架下DASH是服务器端根据收集的状态信息决策传输哪个码率的视频。 Expected Outcomes 前期 两路网络数据集: WiFi+LTE 计算的方式在两条链路上传输视频，每隔固定时间决定是否传输下一个video segment 根据当前播放内容时间标签与已有效缓存内容时间标签距离决定 若传输则利用DRL决策分辨率和包的传输路径，否则等待下一个时隙决定。一般一个周期设为2~4s。 学习训练的环境应利用商业网络trace得到的数据，将来在实际网络环境验证时实际环境与训练环境的网络状态相似的话效果预期应该会比较好。 相似应该主要是带宽，固定测试场所和时间比较容易达到目的。一般环境下带宽越高网络环境越好 希望的训练和测试环境均是单路带宽小于最高分辨率的带宽要求，双路可以弥补单路的不足，提升画质 DASH over Linux kernerl based MPTCP 实现的难关主要在于修改MPTCP scheduler需要改完源码再编译进linux内核测试是否有效，debug会很费精力 硬件要求 一台电脑做服务器(不要求双网卡) 一台电脑配置双网卡，模拟client请求视频。前期可用以太网+无线网卡，后期实际环境可用4G上网卡。 一个路由器，用于两条电脑间组网(理想环境)。利用Linux tc控制带宽，延迟和抖动等服务器端数据。 后期可将服务端部署到云服务器，在商业网络下用无线网卡+4G网卡测试实际环境。]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>DASH</tag>
        <tag>Multipath</tag>
        <tag>DRL</tag>
        <tag>user-perceived QoE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reinforcement Learning and Multipath]]></title>
    <url>%2F2019%2F06%2F24%2FReinforcement-Learning-and-Multipath%2F</url>
    <content type="text"><![CDATA[Reinforcement Learning and MultipathA Reinforcement Learning Approach for Multipath TCP Data SchedulingAbstract the performance of MPTCP is seriously affected by the path environment In order to solve this problem, we propose a new data scheduling algorithm based on reinforcement learning(RL) with the newly introduced Deep Q Network (DQN) framework to enhance the MPTCP data scheduling performance in the asymmetric path. The reinforcement learning algorithm gets the information of every path and adaptively choose the most suitable path by the artificial intelligence. Introduction For instance, paths have huge differences in the round-trip time(RTT), bandwidth resources which may cause a serious decline in performance because the disordered data will fill buffer if the packet cannot deliver to the in time under the limitation of resources in sender and receiver. in this paper, we assume the data scheduling problem and the path selection problem can be formulated as a MDP problem which can be calculated as the reinforcement learning problem. But they all do not consider the transmission from the global perspective that the device can learn from the environment of the path with the help of reinforcement learning.RL Model we use the sending window as the state of agent and the path as the action, so the value function is based on the sending window, the reward and the action. The aim is to optimize path selection to improve the transmission efficiency, and the model needs the information of state, action, and reward to make the decision We define the reward and punishment to impact to path selection. First, if we receive the acknowledgement of successful transmission from the chosen path, there will be a positive 1 reward for this path, but if we can not receive the acknowledgement, no matter the acknowledgement is lost or the data transmission is not finished in deadline, we will punish this path by getting the reward as -1. what is more, if the path is not available now, it will also get the punishment We represent the process of reinforcement learning as a MDP which states are independent Performance Evaluation The simulation is build on the famous Network Simulator version 3(NS3) with the newly added MPTCP module [13] the simulation is established under the heterogeneous condition to simulate asymmetrical networks. ReLeS: A Neural Adaptive Multipath Scheduler based on DRLAbstract ReLeS uses modern deep reinforcement learning (DRL) techniques to learn a neural network to generate the control policy for packet scheduling. It adopts a comprehensive reward function that takes diverse QoS characteristics into consideration to optimize packet scheduling. To support real-time scheduling, we propose an asynchronous training algorithm that enables parallel execution of packet scheduling, data collecting, and neural network training. We implement ReLeS in the Linux kernel and evaluate it over both emulated and real network conditions. Introduction Packet scheduling is a unique and fundamental mechanism for the design and implementation of MPTCP. A scheduler is responsible for determining the amount of data packets to be distributed onto the subflows, which has a significant impact on the performance of MPTCP head-of-line blocking related work The ReMP scheduler [12] duplicates packets over all subflows in exchange for reliability MinRTT, the default scheduler of MPTCP, attempts to fill the congestion window of the subflow with the lowest RTT before advancing to other subflows BLEST [13], a blocking estimation based scheduler, which takes a proactive stand towards minimising HoL-blocking The DEMS scheduler [14] aims at reducing the data chunk download time over multiple paths, whose benefits are maximized when the file size is small or medium In this paper To support online scheduling, the model training process runs offline using the real network traces and updates the online scheduler iteratively. To speedup the training process, we further introduce an asynchronous deep reinforcement learning algorithm that decouples data collection and model training to enable parallel execution of packet scheduling, data collecting, and neural network training. Challenges Multipath packet scheduling should take network heterogeneity (e.g., delay and capacity) into consideration in order to effectively leverage multipath scenarios. Packet scheduling algorithms must balance a variety of QoS goals such as maximizing average throughput, reducing the overall data transfer time, minimizing self-inflicted latency or out-of-order buffer size, and maintaining jitter smoothness Multipath scheduler should adapt to the dynamic of network environments. PROBLEM DESCRIPTION AND SOLUTION FRAMEWORKProblem Description A typical value of SI (scheduling intervals) is 200ms, which is about 3∼4 RTTs An episode is defined as the duration of an MPTCP connection, starting from the initiation of the MPTCP session until its teardown, which may contain several SIs. The scheduler’s goal is to find the best set of split ratios (p1, p2, ··· , pn) for the subflows that lead to the optimal performance Solution Framework Online scheduling: Offline training: The online scheduling and offline training process run asynchronously and iteratively. After each episode the trainer synchronizes the scheduler with the trained neural network in adaption to the environment changes, driving the scheduling policy towards the optimum Training AlgorithmThe deep reinforcement learning task State, At the beginning of each SI, the agent observes the system state Assume in the t-th SI, the system state is represented by $s_t=(s_{t,1},s_{t,2},…,s_{t,n})$, where $s_{t,i}$ is the observed state of the i-th subflow which can be represented by a tuple $s_{t, i}=\left(x_{t, i}, w_{t, i}, d_{t, i}, u_{t, i}, v_{t, i}\right)$. $x_{t,i}$ is the subflow throughput measurement in SI t $w_{t,i}$ is the average congestion window sizes in SI t $d_{t,i}$ is the subflow mean RTT in SI t $u_{t,i}$ is the number of unacked packets in SI t $v_{t,i}$ is the number of retransmitted packets in SI t Action an action is a scheduling decision, which determines how to distribute the current traffic over multiple paths Policy Reward After applying the action, the state of the environment transitions to st+1 and the agent receives a reward by taking the action. A reward function is used to evaluate the long-term performance of MPTCP by for a particular packet scheduling policy. Reward Function $R\left(s_{t}, a_{t}\right)=V_{t}^{\text { throughput }}-\alpha V_{t}^{\mathrm{RTT}}-\beta V_{t}^{\text { lost }}$ Asynchronous Training Algorithm asynchronous training algorithm, which decouples data collection and model learningto enable parallel execution of real-time scheduling and neural network training. Normalized Advantage Function (NAF) [18] framework LSTM. extract features With LSTM, ReLeS can incorporate a large amount of network measurement history into its state space to capture the temporal feature of actual network characteristics. Softmax is used for the final layer activation function in the neural network to form a probability expression of the packet scheduling policy. The asynchronous learning algorithm is summarized in Algorithm 1. The trainer thread takes samples from the replay buffer to update the deep neural network Q-function approximator using stochastic gradient descent. This thread runs on a central server, and dispatches updated neural network parameters to the scheduler thread. The collector thread run on the MPTCP connection sender, and sends the observation, action, and reward in each SI to the central server to append to the replay buffer. asynchronously The trainer keeps training the neural network using the recent experience from the replay buffer the scheduler/collector executes packet scheduling actions on the sender side synchronizes its neural network parameters with the trainer iteratively, and pushes the experience into the shared replay buffer. While $y_t$ is also dependent on $\theta^Q$, directly implementing Q-learning (Eq. 5) with neural network has been proved to be unstable in many environments Because the network Q(s, a|$\theta^Q$) being updated is also used in calculating the targetvalue $y_t$, the Q update is prone to divergence. SYSTEM DESIGN AND IMPLEMENTATION At the sender, the chunk data coming from the application (APP) is stored in the meta buffer, and is then fetched, split, scheduled, and transmitted by the MPTCP scheduler. The policy network generates actions that determine the split ratio of each subflow for packet scheduling. The network states, actions, and rewards in each SI are passed to the collector and stored in a replay buffer, which will be used by the trainer to train the reinforcement learning model and update the policy network. The receiver side logic is much simpler. As shown in Fig. 5, it passively receives or acknowledges the data, reassembles it in the receiver-side meta buffer, and delivers the in-order data to the APP. In the implementation of the system, it requires interaction between the kernel and userspace getsockopt( ) setsockopt( ) PERFORMANCE EVALUATION we implement ReLeS, BLEST [13], and DEMS (the basic DEMS that does not perform reinjection) [14] in the Linux kernel base on MPTCP v0.92 For emulation, we use Linux tc to throttle the bandwidth and to add extra delay on the sender. Linux操作系统中的流量控制器TC（Traffic Control）用于Linux内核的流量控制，主要是通过在输出端口处建立一个队列来实现流量控制。Linux操作系统中的流量控制器TC（Traffic Control）用于Linux内核的流量控制，主要是通过在输出端口处建立一个队列来实现流量控制。 We consider different downloading files sizes varying from 64KB to 256MB to test the performance of the schedulers under different traffic classes. Performance Metrics Application goodput Application delay OFO queue Download time finally make further evaluation under real-world settings Performance Analysis Taking MinRTT as a baseline, the outperformance ratio is defined as the ratio of the number of episodes where ReLeS’s download time is smaller than MinRTT to the total number of episodes Additionally, increasing the number of collectors makes it converge significantly faster The training time is within 0.2 hour for 104 updates, which is efficient. The data collecting consumes much more time than the neural network training, thus, we can achieve significant speedup in overall training time from simultaneously collecting experience across multiple collectors Performance under real-world settings (five locations) office, library, supermarket, dormitory and canteen Google Nexus 5 smartphone - Android 4.4, based on MPTCP v0.86.x Related Work Two widely used scheduling algorithms in MPTCP are MinRTT (default) and Round-Robin, which are simple and heuristic ReMP sends the duplicated data to all subflows to improve reliability in the cost of high redundancy[12] Frommgen et al. [28] proposed a programming model for MPTCP scheduling. Guo et al. [14] developed theoretical analyses to show that having all subflows complete at the same time at the receiver side is a necessary condition for achieving the optimal performance and proposed DEMS ReLeS is a learning-based and experience-driven multipath scheduling approach which is self-adaptive to various kinds of network environments Epressions many efforts have been made in this research [3] put forward what is more, is prone to divergence Different from the existing solutions, the proposed ReLeS is]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>RL</tag>
        <tag>Multipath</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Video Transmission via Multipath]]></title>
    <url>%2F2019%2F06%2F20%2FVideo-Transmission-via-Multipath%2F</url>
    <content type="text"><![CDATA[Video transmission via MultipathCross-Layer Scheduler for Video Streaming over MPTCPAbstract Our objective is to maximize the amount of video data that is received in time at the client Keyword: Packet scheduling, Cross-Layer Scheduler Introduction MPTCP is expected to enable quicker and more stable communication by concurrently exploiting several network paths head-of-line 排头阻塞 出现在缓存式通信网络交换中的一种现象,这就如同你在只有一条行车路线的马路上右转，但你前面有直行车，虽然这时右行线已经空闲，但你也只能等待。 We focus on the multipath streaming of a video. Our objective is to increase the quality of experience (QoE) of the viewers by maximizing the reception of decodable video data in difficult conditions (video bit-rate close to the available bandwidth and small application buffer). Our proposal applies to both live and on-demand services Contributions cross-layer scheduler leverages information from both application and transport layers theoretical analysis Integer Linear Program These traces in dataset include the timestamps of both sending and arrival times of each packet in each path. video-aware BackgroudMulti-Path Networking Application Sending Buffer Multi-Path Sending Buffer TCP Sending Buffer Receiving Buffer MPTCP implements only one receiving buffer, which gets all incoming packets from all subflows before the delivery to the application. Application Receiving Buffer The recent research activities related to multi-path transport protocols, such as Concurrent Multipath Transfer SCTP (CMT-SCTP) or MPTCP, have dealt with the scheduling of packets at the Multi-Path Sending Buffer (which packets to send to which TCP Sending Buffer) [2, 22, 25] and the management of retransmission in case of packet losses CMT-SCTP features the same coupled congestion control as MPTCP (Opportunistic Linked-Increases Algorithm (OLIA) [20, 26]) but it has no default options, so parameter setting is hard, and it suffers from deployment issue since it is based on SCTP Multimedia Stream Structure The bit-stream is cut into frames, which have temporal dependencies with regards to their types: Intra (I), Predicted (P) or Bidirectional (B) pictures Existing Work on Carrying out Video Through Multiple Paths In the multimedia community, papers have mostly focused on the application level (a seminal work is [19]). In the network community, a research axis is to deal with streaming in specific wireless environment (for example [8]). Our paper is between these approaches (without any assumption on the physical layer). The scheduler is identified as one key component driving the performance of MPTCP [4] but some other approaches have also been considered. These proposals are in line with the services the TAPS working group at the IETF aim to provide: smart interactions between the multi-path transport and the video generation to improve QoE. Video-content aware scheduler over MPTCP Particularly, data are transmitted from the MPTCP Sending Buffer in the same order as they arrived to this buffer, even if some data should no longer be sent, for example an obsolete video unit whose playback deadline has already expired. Such an event is likely to occur in transport protocols that guarantee in-order delivery, such as TCP and MPTCP because the loss of one data packet can delay the delivery of multiple following packets. Passing Information between the Different Layers Video content awareness The cross-layer layer knows all those dependencies and so is able to infer whether the client can decode a video unit at a specific time or not. Each video unit is associated with a specific video frame (even for tiles) Network awareness The cross-layer scheduler knows the status of the network, including the smoothed Round-Trip Time (sRTT), the global moving average bandwidth and the loss probability of each path With the sRTT, the cross-layer scheduler can estimate the arrival time of each packets, and choose to send a video unit close to its deadline on the path with the shortest sRTT. From the moving average bandwidth, the scheduler can choose to drop some less important video units to favor others. From the loss probability, it can choose to send highly important video units on the path with the smallest loss probability the cross-layer scheduler needs to implement a feedback loop from the MPTCP socket. Although such feedback does not exist in open-source implementations yet, the development is not challenging since the server hosts both the MPTCP implementation and the application. Application awareness The cross-layer scheduler knows the status of the video player on the client. It can estimate the lag at the client side. From the lag, the start timestamp and the POC, the cross-layer scheduler can estimate the deadline of each video unit. The client can add extra information in its HTTP requests or use Real-Time Transport Control Protocol (RTCP) to implement this feedback in practice. The lag is a fixed value, which can be communicated to the server. The hardest thing is to estimate the timestamp when the client starts playing the decoded video. Algorithm The goal of our algorithm is to prioritize the video units that are the most likely to be received in time The crosslayer scheduler is content-aware (it knows how to extract video units) and application-aware (it is able to estimate their playback deadline from an applicative feedback loop). It is also network-aware (it knows which path the MPTCP stack selects to send the next packet as well as the sRTT of this path) MPTCP DATASET for each packet, the transmission timestamp, the reception timestamp, the size of the payload and the path on which this packet has been carried. Expressions The term video unit can be interpreted as either frame or tile]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>Multipath</tag>
        <tag>Video</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[a summary of recent 4 blogs of paper]]></title>
    <url>%2F2019%2F06%2F11%2Fa-summary-of-recent-4-blogs-of-paper%2F</url>
    <content type="text"><![CDATA[数据中心的数据拷贝路径的选择(BDS: A Centralized Near-Optimal Overlay Network for Inter-Datacenter Data Replication) EuroSys 2018Abstract pair-wise inter-DC data transfer is good, but insufficient to optimize bulk-data multicast. this is due to fail to explore the capability of servers to store-and-forward data as well as the rich inter-DC overlay paths that exist in geo-distributed DCs. fully centralized architecture: a central controller to maintain an up-to-date global view of data delivery status of intermediate servers control algorithm: selection of overlay paths and scheduling of data transfers Overview of BDS Centralized control: At a high level, BDS uses a centralized controller that periodically pulls information (e.g.,data delivery status) from all servers, updates the decisions regarding overlay routing, and pushes them to agents running locally on servers The key to realizing centralized control: the design of BDS performs a trade-off between incurring a small update delay in return for the near-optimal decisions brought by a centralized system. Tricks: Decoupling scheduling and routing it groups the blocks with the same source and destination pair to reduce the problem size the routing step is reduced to a mixed-integer LP problem it uses the improved fully polynomial-time approximation schemes (FPTAS) to optimize the dual problem of the original problem and works out an ε-optimal solution. 视频监控分析中视频传输参数(码率)的选择 (Reinventing Video Streaming for Distributed Vision Analytics) HotCloud 2018Abstract we call upon this community to similarly develop custom streaming protocols for better analytics quality (accuracy) of vision analytics (deep neural networks). improve the tradeoffs between bandwidth usage and inference accuracy the new protocols can directly optimize the inference accuracy while minimizing bandwidth usage Practical Design Server-driven protocol as active learning: The workflow of a server-driven protocol closely resembles an active learning process Sending a video segment at a high resolution or a higher sampling rate to the server can be seen as labeling more bits in the region Iterative workflow using superposition coding the client first sends a base-quality video (e.g., low resolution or frames sampled sparsely in time) to the server if the inference output is not confident, the server decides to get additional information so that it can recover higher-quality video by “adding” the new data to the base-quality video it already has. superposition coding 视频监控分析中神经网络架构的选择 (Chameleon: Scalable Adaptation of Video Analytics) SIGCOMM 2018Abstract to balance resource and accuracy by selecting a suitable NN configuration (e.g., the resolution and frame rate of the input video) dynamically picks the best configurations for existing NN-based video analytics pipelines. tradeoff: adapting configurations frequently can reduce resource consumption with little degradation in accuracy, but searching a large space of configurations periodically incurs an overwhelming resource overhead that negates the gains of adaptation. Overview of Chameleon quantify the impact of spatial and temporal correlations on resource-accuracy tradeoffs present a suite of techniques to dramatically reduce the cost of periodic profiling by leveraging the spatial/temporal correlations. 处理large action space（利用action的时间和地理相关性聚类做决定；利用独立性将参数的指数空间$n^m$降低到O(nm)） temporal correlations the one with the lowest cost meeting the accuracy threshold α, might change frequently, the set of top-k best configurations (top-k cheapest configurations with accuracy ≥ α) tend to remain stable over time. Thus, we can dramatically reduce the search space by focusing on these top-k configurations. spatial correlations if two video feeds share similar characteristics, it is likely they will also share the same best configurations. Such cross-camera correlations provide an opportunity to amortize profiling cost across multiple camera feeds the configuration knobs independently impact accuracy: it lets us tune the resolution knob independent of the frame rate; this prunes a large part of the configuration space it lets us estimate a configuration’s accuracy by combining its perknob accuracies; in particular, we can do this withoutrunning the expensive golden configuration. 在网络中应用DL待解决的问题 (Demystifying Deep Learning in Networking) APNet 2018Abstract we call upon this community to similarly develop techniques and leverage domain-specific insights to demystify the DNNs trained in networking settings unleash the potential of DNNs in an explainable and reliable way Interpretability and Integrating Domain Knowledge Interpretability saliency map a heatmap showing how much impact of each input feature on the output When a DNN comprises convolutional layers, the Grad-CAM [14] method can be employed to generate the saliency map From input to high-level features distinguishable input we can actually explain correlation by DNN works internally: the intermediate neurons are only activated when the job size is over or below certain thresholds, i.e., the neurons effectively act as a “filter” of job size. Maximally activating intermediate neurons Integrating domain knowledge key ideas Better transferability Better robustness Better training efficiency Regulating DNNs with domain knowledge The basic idea is to use two processes, called “teacher” and “student”, to regulate the training of a DNN f with a domain-specific logic g Both f and g take input x and output a probability distribution y over the action space student” trains f such that it minimizes the difference to the ground truth as well as the difference to the output of g.]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Demystifying Deep Learning in Networking]]></title>
    <url>%2F2019%2F06%2F10%2FDemystifying-Deep-Learning-in-Networking%2F</url>
    <content type="text"><![CDATA[Abstract The problem of model opacity would eventually impede the adoption of DNN-based solutions in practice we call upon this community to similarly develop techniques and leverage domain-specific insights to demystify the DNNs trained in networking settings, and ultimately unleash the potential of DNNs in an explainable and reliable way Neural networks, Resource allocation, Interpretability Introduction Studies from academia and industry have shown remarkably promising improvements by DNN-based solutions (e.g., deep reinforcement learning) in a variety of classic problems, such as cloud resource allocation [10], end-to-end video adaptation [11], routing [17], wireless bandwidth allocation [18], and so forth The inability to understand these deep models lies at the root of a multitude of concerns; e.g., it is difficult to completely trust the model will perform well in new environments, to debug why a wrong decision was made, and to defend it against adversarial manipulation. key aspect of DNNs for networking How is a decision made? When will it fail? Can domain-specific insight be integrated? WHY IS INTERPRETABILITY CRUCIAL? Early promises of DNNs Each problem is formulated as a reinforcement learning process, in which the key step is to use a DNN to map an input “state” to a probability distribution over “actions”. Each action triggers a reward (e.g., job slowdown), and the DNN updates its parameters to maximize expected reward until they converge Concerns of treating DNNs as blackboxes Hard to confer causality Hard to trust Incompatible with domain-specific knowledge the opacity of DNNs makes incorporating domain-specific knowledge difficult. WHY DNN MAKES THE DECISION？ Important features The input of a DNN often includes all features that might be useful in the decision-making To reveal what features a DNN depends on, a popular technique is to use saliency map [15], which is a heatmap showing how much impact of each input feature on the output When a DNN comprises convolutional layers, the Grad-CAM [14] method can be employed to generate the saliency map. So if the resource demand of a job is labeled dark red (or blue) in the saliency map, it means increasing the resource demand of that job will greatly increase (or reduce) the chance of making the same decision From input to high-level features Maximally activating intermediate neurons: (In)distinguishable input In contrast, by examining the intermediate neurons, we can actually explain correlation by DNN works internally: the intermediate neurons are only activated when the job size is over or below certain thresholds, i.e., the neurons effectively act as a “filter” of job size. Such interpretation is more generalizable and reliable Research thrusts domain knowledge is needed it is indeed plausible to test domain-specific hypothesis by visualizing/interpreting features and high-level representations of DNNs used in networking/systems settings. WILL IT FAIL MISERABLY Adversarial input states the generated input state needs to be meaningful Heterogeneous environments In contrast, machine learning-based algorithms can optimize performance for workloads drawn from the same distribution as the training data, but for the algorithm to carry over to a different environment requires the additional transferability a DNN can fail miserably when tested against data draw from an unseen distribution, even when it is simple enough to be handled by simpler alternative models Research thrusts MACHINE-GENERATED ALGORITHMS TO RULE IT ALL? Integrating domain knowledge is the key Better transferability Better robustness Better training efficiency Regulating DNNs with domain knowledge The basic idea is to use two processes, called “teacher” and “student”, to regulate the training of a DNN f with a domain-specific logic g Both f and g take input x and output a probability distribution y over the action space “student” trains f such that it minimizes the difference to the ground truth as well as the difference to the output of g. Expressions The problem of model opacity would eventually impede the adoption of DNN-based solutions in practice is incompatible with opaque models like DNNs不透明的模型 which could otherwise achieve the best of both worlds causality因果关系 Without a proper understanding of the causality, we will not be able to trust if DNN works the same way we believe it does rule-based models is amenable to 经得起检验的 most techniques are derived from the aforementioned formulation.]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>DNN in networking</tag>
        <tag>interpretability</tag>
        <tag>domin-specific knowledge</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chameleon: Scalable Adaptation of Video Analytics]]></title>
    <url>%2F2019%2F06%2F09%2FChameleon-Scalable-Adaptation-of-Video-Analytics%2F</url>
    <content type="text"><![CDATA[Abstract to balance resource and accuracy by selecting a suitable NN configuration (e.g., the resolution and frame rate of the input video) We present Chameleon, a controller that dynamically picks the best configurations for existing NN-based video analytics pipelines. tradeoff: adapting configurations frequently can reduce resource consumption with little degradation in accuracy, but searching a large space of configurations periodically incurs an overwhelming resource overhead that negates the gains of adaptation. keywords: vedio analytics, DNN, object detection Introduction The pipeline has several “knobs” such as frame resolution, frame sampling rate, and detector model (e.g., Yolo, VGG or AlexNet). We refer to a particular combinations of knob values as a configuration. The “best” configuration is the one with the lowest resource demand whose accuracy is over a desired threshold While prior video analytics systems [16,32, 33] profile the processing pipeline to minimize cost, they only do so once, at the beginning of the video。忽略了内在的动态性 In fact, in our early experiments, the cost of periodic profiling often exceeded any resource savings gained by adapting the configurations. The main challenge, thus, is to significantly reduce the resource cost of periodic configuration profiling. leverages domain-specific insights on the temporal and spatial correlations of these configurations. Temporal correlation: The top-k best configurations (cheapest k configurations with accuracy above the desired threshold) tend to be relatively stable over time, for a small value of k. configurations that are very bad—very inaccurate and/or very expensive— remain so over long time periods. we can significantly prune the search space during profiling by learning which configurations are promising and which are unhelpful. Cross-camera correlation: Once we identify a good set of configurations for one video feed, we can reuse it on similar feeds Independence of configurations: for a given configuration knob, the relationship between its resource and accuracy is largely independent of the values of the other configuration knobs. Contributions We do a cost-benefit analysis for continuously adapting NN configurations compared to one-time tuning We identify and quantify the impact of spatial and temporal correlations on resource-accuracy tradeoffs We present a suite of techniques to dramatically reduce the cost of periodic profiling by leveraging the spatial/temporal correlations. RECOURCE-ACCURACY PROFILES Object detection pipelines Pipelines Configurations Pipeline A has 150 configurations and Pipeline B has 20. Performance of configurations Accuracy we compute accuracy of a single frame by comparing the detected objects with the objects detected by the most expensive configuration, which we call the golden configuration, using the F1 score Cost We use average GPU processing time (with 100% utilization) per frame as the metric of resource consumption Performance impact we show that the relationship between configuration and accuracy has great temporal variability, so dynamically adapting the configuration can lead to better resource-accuracy tradeoffs Prohibitive profiling cost A sizable component of this profiling cost comes from running the golden configuration. Challenges in reducing profiling cost profiling cost includes the cost of running the golden configuration, which itself can be prohibitively expensive. simply increasing the update interval T does not help in practice. POTENTIAL OF ADAPTATION Quantifying potential One-time update Periodic update KEY IDEAS INCHAMELEON if the NN configurations’ resource-accuracy tradeoff is affected by some persistent characteristics of the video, we can learn these temporal correlations to reuse configurations over time More generally, even though the best configuration, i.e., the one with the lowest cost meeting the accuracy threshold α, might change frequently, the set of top-k best configurations (top-k cheapest configurations with accuracy ≥ α) tend to remain stable over time. Thus, we can dramatically reduce the search space by focusing on these top-k configurations. if two video feeds share similar characteristics, it is likely they will also share the same best configurations. Such cross-camera correlations provide an opportunity to amortize profiling cost across multiple camera feeds we can leverage the fact that similar videos tend to have similar distributions of best configurations. Then, we can use the most promising configurations from one camera—e.g., the top-k best configurations—to guide the profiling of a spatially-related camera. we have experimentally observed that many of the configuration knobs independently impact accuracy, allowing us to avoid an exponential search这点很重要啊 说明参数的独立性 it lets us tune the resolution knob independent of the frame rate; this prunes a large part of the configuration space it lets us estimate a configuration’s accuracy by combining its perknob accuracies; in particular, we can do this withoutrunning the expensive golden configuration. CHAMELEON TECHNIQUES Overview Chameleon uses a solution inspired by greedy hill climbing that exploits the independence of NN configuration knobs to reduce the search space from exponential to linear (§5.4). Using this profiling method, it leverages the temporal persistence of configurations to learn their properties over time and amortizes the cost of profiling across multiple cameras by leveraging cross-video similarities Temporal incremental updates Cross-video inference Grouping related videos Profiling a video segment Chameleon leverages the empirically-driven assumption from §4.3 that the knobs of our NN configurations can be treated independently. greedy hill climbing, where each knob is tuned while all other knobs are held fixed, reducing the search space from $n^m$ to O(mn). since our knobs exhibit monotonically increasing/decreasing performance, we can stop the loop when performance is good enough (or bad enough, depending on the search direction) EVALUATION dataset: a dataset of video streams from five traffic video cameras deployed in different intersections in a metropolitan area (Bellevue, WA). FUTURE WORK Network bandwidth Profiling on the edge Triggering the profiling Expressions improving inference accuracy often requires a prohibitive cost in computational resources factory floor 工厂车间，工人工作的地方]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>video analytics</tag>
        <tag>configuration</tag>
        <tag>top-k</tag>
        <tag>Persistent characteristics over time</tag>
        <tag>Cross-camera similarities</tag>
        <tag>Independence of configuration knobs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reinventing Video Streaming for Distributed Vision Analytics]]></title>
    <url>%2F2019%2F06%2F09%2FReinventing-Video-Streaming-for-Distributed-Vision-Analytics%2F</url>
    <content type="text"><![CDATA[Abstract in this paper, we call upon this community to similarly develop custom streaming protocols for better analytics quality (accuracy) of vision analytics (deep neural networks). We highlight new opportunities to substantially improve the tradeoffs between bandwidth usage and inference accuracy the new protocols can directly optimize the inference accuracy while minimizing bandwidth usage Introduction Video analytics, in contrast, focus onlyon specific video segments with queried objects of interest. Thus, a streaming protocol is optimal as long as the frames with the queried objects of interest are sent at sufficiently high resolution. What’s new about video streaming in vision analytics? the video needs to be streamed to cloud or edge servers (as shown in Figure 1) to offload the computationally intensive DNN-based vision tasks A video streaming protocol can be seen as a function that applies some compression operation p(·) (e.g., resolution downsizing and frame sampling) on the original video v, and sends the compressed video p(v) to the server. color changes in background trigger the client to send many frames while the actual objects of interest are static This client-driven workflow, however, suffers from the fundamental limitation that, without any input from the server, it is difficult to predict precisely what the server needs, i.e., how much information is needed to encode all objects of interest. A case for a server-driven approach maximizes the analytics accuracy by giving the server full (or partial) control over what to send from the client to the server The oracle protocol (unrealistically) assumes that the server can access the original video and pick the optimal values for each of the control knobs–frame selection, area cropping, resolution, and compression level. That is, it selects the exact frames where the objects move, crops out only the spatial regions that contain objects, selects the minimal resolution at which the server-side logic can detect the object, etc. Challenge the inference result on low-quality video (e.g., low resolution, low frame rate, or aggressive compression), while not accurate, is sufficient to reveal what additional information is needed by the NN model to achieve higher accuracy. Inference results on low-resolution frames can indicate where objects are likely to appear Inference results on sparsely sampled frames can indicate which frames are likely to contain objects. Towards a practical design Formalizing server-driven protocol Iterative workflow using superposition coding the client first sends a base-quality video (e.g., low resolution or frames sampled sparsely in time) to the server, and if the inference output is not confident, the server decides to get additional information so that it can recover higher-quality video by “adding” the new data to the base-quality video it already has. superposition coding Server-driven protocol as active learning The workflow of a server-driven protocol closely resembles an active learning process Sending a video segment at a high resolution or a higher sampling rate to the server can be seen as labeling more bits in the region A concrete design and its early promise SimpleProto, a simple server-driven protocol that achieves substantial improvement. Open issues Tighter integration with client/server analytics stack Leveraging insights from computer vision literature Expressions ubiquitously available cameras 无所不在的摄像头 its high cost prohibits a scalable solution, especially …prohibits阻止了]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>video analytics</tag>
        <tag>server-driven</tag>
        <tag>superposition coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BDS: A Centralized Near-Optimal Overlay Network for Inter-Datacenter Data Replication]]></title>
    <url>%2F2019%2F06%2F09%2FBDS-A-Centralized-Near-Optimal-Overlay-Network-for-Inter-Datacenter-Data-Replication%2F</url>
    <content type="text"><![CDATA[Abstract pair-wise inter-DC data transfer is good, but insufficient to optimize bulk-data multicast. this is due to fail to explore the capability of servers to store-and-forward data as well as the rich inter-DC overlay paths that exist in geo-distributed DCs. an application-level multicast overlay network for largescale inter-DC data replication fully centralized architecture: a central controller to maintain an up-to-date global view of data delivery status of intermediate servers control algorithm: selection of overlay paths and scheduling of data transfers Introduction inter-DC multicast already amounts to 91% of inter-DC traffic the performance of inter-DC multicast could be substantially improved by sending data in parallel via multiple overlay servers acting as intermediate points to circumvent slow WAN paths and performance bottlenecks in DC networks Demonstrating the practical benefits of BDS by a realworld pilot deployment in Baidu (没有渠道，这是一个需要级别和百度技术支持以及工作量的事情) A CASE FOR APPLICATION-LEVELINTER-DC MULTICAST OVERLAYS The basic idea of an application-level overlay network is to distribute traffic along bottleneck-disjoint overlay paths it does not have per-hop bandwidth information of each multicast transfer. Instead, we observethat if two overlay paths have different end-to-end throughput at the same time, they should be bottleneck-disjoint.给出了鉴别bottleneck-disjoint路径的一个方法 Limitations of existing solutions Inefficient local adaptation. Interaction with latency-sensitive traffic Key Observations Inter-DC multicasts amount to a substantial fraction of inter-DC traffic, have a great variability in sourcedestination, and typically last for at least tens of seconds. Bottleneck-disjoint overlay paths are widely available between geo-distributed DCs. Existing solutions that rely on local adaptation can have suboptimal performance and negative impact on online traffic. Overview of BDS Centralized control: suboptimal performance due to lack of global view or orchestration At a high level, BDS uses a centralized controller that periodically pulls information (e.g.,data delivery status) from all servers, updates the decisions regarding overlay routing, and pushes them to agents running locally on servers when the controller fails or is unreachable, BDS will fall back to a decentralized control scheme to ensure graceful performance degradation to local adaptation empirical observations: Large decision space: difficult for individual servers to explore all available overlay paths based only on local measurements. improve overlay multicast performance by maintaining a global view of data delivery status of all servers Large data size BDS can tolerate a short delay (of a few seconds) Strict traffic isolation: it is simpler to allocate bandwidth of each data transfer by controlling the sending rate at all servers in a centralized fashion avoid excessive bandwidth usage that negatively impact the latency of delay-sensitive traffic Lower engineering complexity: the centralized architecture moves the control complexity to the centralized controller, making BDS amenable to a simpler implementation The key to realizing centralized control the design of BDS performs a trade-off between incurring a small update delay in return for the near-optimal decisions brought by a centralized system. NEAR-OPTIMAL AND EFFICIENT DECISION-MAKING LOGIC Decoupling scheduling and routing the routing step is reduced to a mixed-integer LP problem it groups the blocks with the same source and destination pair to reduce the problem size it uses the improved fully polynomial-time approximation schemes (FPTAS) [17] to optimize the dual problem of the original problem and works out an ε-optimal solution. System Design BDS uses two additional optimizations to make the workflow more efficient Blocks merging Non-blocking update Dynamic bandwidth separation BDS uses 80% link utilization as a “safety threshold” BDS, in contrast, dynamically monitors the aggregated bandwidth of delay-sensitive applications, and calculates the residual bandwidth to be used by inter-DC multicast while meeting the safety link utilization threshold Evaluation Using a combination of pilot deployment in Baidu’s DCs RELATED WORK Overlay Network Control. Data Transfer and Rate Control Centralized Traffic Engineering ideas 中继的选择 速率的选择 Expressions amount to 10% of … in a fraction of second 零点几秒 this is four orders of magnitude faster than 快4个数量级 it is vital that 至关重要的是]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>datacenter</tag>
        <tag>data replication</tag>
        <tag>overlay path</tag>
        <tag>scheduling and routing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Phd_Thesis_JunchenJiang_Notes]]></title>
    <url>%2F2019%2F05%2F15%2FPhd-Thesis-JunchenJiang-Notes%2F</url>
    <content type="text"><![CDATA[Abstract Keywords: Internet applications, Quality of Experience, Data-Driven Networking, user-perceived The key contribution of this dissertation is to bridge the long-standing gap between the visibility to user-perceived QoE and the visibility to network conditions by a data-driven approach. improve QoE by maintaining a global view of up-to-date network conditions based on the QoE information collected from many endpoints. session-level our solutions can yield substantial QoE improvement and consequently higher user engagement for video streaming and Internet telephony than existing solutions as well as many standard machine learning solutions. Introduction about DDN two broadly defined classes of prior approaches to optimize QoE In-network approaches: better designs of in-network devices (e.g., routers, switches, and middleboxes) and routing schemes. lack of visibility to userperceived QoE Endpoint approaches: using intelligent logic running at individual endpoints to react to changes in network conditions. limited by individual endpoints’ local visibility to network conditions DDN’s features Compared to in-network approaches, DDN can monitor client-side applications and thus can directly optimize user-perceived QoE, rather than indirect low-level metrics. Compared to endpoint-based approaches, DDN compensates the lack of visibility of network conditions at one endpoint by a real-time, global view of QoE observed from many endpoints, thus addressing the key limitation of the endpoint adaptation. improve QoE by using a logically centralized controller (as illustrated in Figure 1.1) which maintains a global view of real-time network conditions by gathering QoE measured from many application sessions and uses this global view to make optimal decisions regarding the adaptation of individual sessions use realworld deployment and large-scale emulation to demonstrate that our solutions can substantially improve the QoE of video streaming and Internet telephony.我觉得我们这里根本做不到 几种方法： CFA: a video QoE prediction system that can accurately predict the quality of a video client if it uses certain CDN and bitrate DDA：a throughput prediction system to accurately predict end-to-end throughput at the beginning of a video session to help determine the highestyet-sustainable initial bitrate group-based exploration-exploitation：decomposes the global exploration-exploitation process of all sessions into subprocesses guided exploration: instead of exploring the whole decision space of all possible relay choices, learns a small set of promising relays for each AS pair based on long-term (e.g., daily) historical data, and explores these promising relays using most calls in near real time. video QoE is measured by buffering time, start-up delay, and average bitrate, each of which has been shown to have strong correlation with user engagement in multiple studies.While subjective metrics can directly reflect user satisfaction, we chooseto use these objectively measurable metrics as a proxy for real user satisfaction for two reasons: (1) they can be passively collected en masse by instrumentation code running in client devices without any user input, and (2) they are less noisy than subjective metrics which can be affected by factors (e.g., content or personal preference) beyond the scope of this dissertation. QoE和选择objectively measurable metrics判定用户满意度的原因。 QoE Video QoE metrics: buffering ratio; join time; average bitrate; join failures. Dataset: based on client-side measurements of video quality from over 300 million sessions over a duration of two weeks. The unique feature of our dataset is that it is collected over 379 distinct content providers spanning diverse genres, both live and video-on-demand content, different content delivery platforms, different types of bitrate adaptation algorithms, and device/browser platforms. VoIP QoE metrics: poor call rate (PCR) dataset: The dataset from Skype consists of a sampled set of 430 million audio calls drawn from a seven month period. VoIP QoE distribution: The results show that a significant fraction of calls (over 15%) occur on paths with RTT over 320ms, or loss over 1.2%, or jitter more than 12ms, which we pick as our thresholds for poor performance. Internet Video 播放速率控制 Early Internet video technologies: Apple QuickTime, Adobe Flash RTMP (based on connection-oriented video transport protocols) new generation of Internet video technologies: Microsoft Smooth Streaming, Apple’s HLS, Adobe’s HDS (全部都是HTTP-based adaptive streaming protocols) HTTP-based adaptive streaming protocols’ advantages: three points Internet Telephony managed overlay approach enjoys several practical benefits: three points Improve QoE Prior Work on Quality Optimization Taxonomy Where in the network? endpoint-based solutions (clients, servers, caches)and in-network solutions (switches, routers). Which level in the protocol stack? Lower levels and Application Design trade-offs More visibility to user-perceived QoE More visibility to network conditions In-Network Solutions IP-layer support for QoS: novel QoS service architecture Router-assist congestion control SDN-based approach Endpoint Solutions Overlay routing Congestion control Application-level adaptation Network performance prediction: to use packet-level probes to estimate end-to-end performance; to build an “Internet performance map” based on active probes from a selective set of “vantage points”; to leverage the history of the same client-server pair evaluation of performance QoE metrics - we need to optimize user-perceived QoE Video measurements Prior Work on Data-Driven Optimization in Networking Better Settings of Parameters: While these efforts are in entirely different areas, they have largely exploited the same inefficacy in traditional control logic that the parameters arestatically configured based on assumptions that are ill-matched with the dynamic workload inruntime.Such problem can be fixed by dynamically training these parameters with recent measurements or synthetically simulated data. Better Run-Time Decisions: In other word, rather than inferring the underlying network states and finding best decisions analytically, it builds a model that directly associate quality feedback with decisions (configurations). Research has shown that this more direct data-driven approach can improve the performance of routing [181], TCP throughput [89], server selection in web performance [146], as well as bitrate adaptation in video streaming [150]. (这不就机器学习吗) exploration-exploitation strategies (multi-armed techniques [215]), or Bayesian optimization Data-Driven Network Formalizing DDN DDN is a new paradigm for designing the adaptation logic of end-to-end protocols (such as adaptive video streaming protocols) DDN-based control loop is driven by real-time multi-session (not single-session) view of in-situ quality [100] measurement (not active measurements or indirect metrics), and automatically tuned actuation algorithms based on data-driven insights (with little to no manual tuning). A DDN-enabled protocol has two additional components: (a) the client-side instrumentation code which runs inside client-side application to measure client-perceived quality of each session and applies decisions made by DDN; and (b) the DDN controller which runs two loosely coupled steps:(controller收集client的信息，controller做决定，client执行) Aggregate quality measurement from client-side instrumentation into a global view of upto-date network conditions and some actionable insights. Make control decisions based on the actionable insights, and send them to client-side instrumentation for execution. Application Level, Session Level Compared to prior work on data-driven optimization in networking (1) The input data of DDN is much larger both in scale and scope, allowing DDN to learn a more accurately model of the network conditions and make more informed decisions. (多个session) (2) The input data of DDN is collected from concurrent and history sessions that have different session-level features (client-side, network-level, and server-side), so the DDN decision logic must take into account the potentially complex relationship between these session-level features and QoE. Several early applications of DDN from prior work CDN/bitrate selection for video: a DDN controller that maps a video session to the CDNand bitrate that has the best quality on similar sessions Relay selection for Internet telephony: improvement on call quality by selecting optimal relay servers for each call Online service cluster selection： By measuring end-to-end quality from clients and dynamically modeling the workload of network paths and servers, it can select proxies that reduce mean latency by 60% and carry 2× more traffic, compared with a baseline that finds proxies by Anycast. File sharing: predict the throughput between a client and a server Challenges for DDN Need for Expressive Models The algorithmic objective of DDN is to build a model that maps each session in the session-level feature space to the optimal decision in the decision space High-dimensional relationship between session-level features and QoE: we observe a combinational effect where video QoE is affect by a specific combination of feature values, but does not appear to be correlated with any individual feature an accurate QoE prediction model must be expressive enough to capture all these spatial and temporal complexities. Large decision spaces: needs to find a good relay path for each VoIP call in a set of hundreds of relay points. Need for Scalable Platforms Global view vs. data freshness: 分布式的缺少global view，中心式的缺少对fresh data的考虑 Near real-time predictive analytics、 How Intuitively Persistent Critical Structures Address the Challenges? Reducing session-level feature spaces: The advantage of persistentcritical structures is that each session’s QoE only depends on by a few critical features (rather than all features).(怎么确定critical features成了另外一个问题) Reducing large decision spaces: reduce the decision set to a subset of most promising decisions which can be explore efficiently Decomposing the decision-making process: To make decisions for the sessions in a group, we can use a logic that runs in the same frontend cluster where their fresh data is collected, and that uses only the information of these similar sessions to make decisions. (backend分组，每组的frontend make desicion) Learning the persistent critical structures from data: 事实上是最难的 Making DDN Practical by Persistent Critical Structures (DDN一般的流程) Critical Features Analysis：each video session has a small set of critical features that ultimately determines its video quality, and these critical features change much more slowly than video quality Group-Based Control:the clients that exhibit similar QoE behavior will have similar network-level features (e.g., same IP prefix), and thus their fresh data will likely be collected by the same frontend cluster Guided Exploration: the stability of promising relay choices: for each pair of caller AS and callee AS, there is a small and stable subset of relays that almost always contains the best relay. Structural Analysis of QoE Problems In this chapter, we present empirical evidenceof these persistent critical structures by using a large-scale structural analysis on the video and VoIP QoE Internet Video Methodology Dataset: The dataset consists of client-side measurements of video quality from over 300 million sessions of 379 distinct content providers spanning diverse genres, both live and video-on-demand content, different content delivery platforms, different types of bitrate adaptation algorithms, and device/browser platforms Session-level features: ASN、CDN、Content provider (Site)、VoD or Live、Player type、Browser、Connection type(mobile/fixed wireless, DSL, fiber-to-home) Identifying problem sessions:join failures, buffering ratio, bitrate, join time Identifying problem clusters Identifying critical clusters: Temporal Patterns Spatial Patterns Predictive QoE Optimization By Critical Feature Analysis improves video QoE by formulating DDN as a prediction problem video quality can be substantially improved by optimally selecting the best CDN and bitrate for each video session Critical Feature Analytics Challenge Challenge 1: Complex QoE-Determining Factors High-dimensional relationship between video quality and session features Limitation of existing solutions Highly diverse structures of factors: The factors that affect video quality vary across different sessions. This means the prediction algorithm should be expressive enough to predict quality for different sessions using different prediction models. Challenge 2: Fresh Updates prediction error increases dramatically if the staleness exceeds 10 minutes The requirement to use the most recent measurements makes it infeasible to use computationally expensive models. Overview of CFA Ideas Baseline Prediction Algorithm At a given time, video sessions having same value on every feature have similar video quality. In our dataset, more than 78% of sessions have no identical session (i.e.,matching on all features) within the last 5 minutes. Critical Features Each video session has a subset of critical features that ultimately determines its video quality. First, find the critical features of each session s, denoted as CriticalFeatures(s). Then, find similar sessions that match values with s on critical features CriticalFeatures(s) within a recent history of length ∆ (by default, 5 minutes). Finally, return some suitable estimate of the quality of these similar sessions Design of CFA Critical features tend to persist on long timescales of tens of minutes. Learning Critical Features Persistence implies that critical features of a session are learnable from history Using Fresh Updates Persistence implies that critical features can be cached and reused over tens of minutes. On the timescale of tens of minutes, we update the results of critical feature learning. Then, on a faster timescale of tens of seconds, we update quality estimation using fresh data and the most recently learned critical features. This decoupling minimizes the impact of staleness on prediction accuracy. Implementation and Deployment Centralized backend: By default, critical feature learning runs every 30 minutes, and quality estimation runs every minute. Distributed frontend Real-time query/response and decision makers of CDN/bitrate are colocated in distributed frontend clusters that are closer to clients than the backend Each frontend cluster receives the quality function from the backend and caches it locally for fast prediction. Relationship to existing ML techniques Multi-armed bandit algorithms [215] find the decision with the highest reward (i.e., best CDN and bitrate) from multiple choices. The feature selection problem [106] seems similar to critical feature learning, but with a key difference: critical features vary across video sessions Cross-Session Throughput Prediction for Initial Video Bitrate Selection 初始视频码率的选择 Backgroud Existing approaches to initial bitrate selection, however, are inefficient A video player should ideally pick the highest initial bitrate that is sustainable Dataset FCC dataset: This dataset consists of 9.9 million sessions and is collected from 6204 clients in US spanning 17 ISPs. Supplementary VoD dataset: 0.8 millions VoD sessions, collected by a major video content provider in China. 中国哪家的啊。。。都没看到怎么获取 Design of DDA Insight of DDA DDA finds for a given session a prediction model between the Nearest Neighbor and Global prediction models, so that it strikes a balance between being closer to Nearest Neighbor for accuracy and being closer to Global for reliability Second, instead of mapping all sessions to the same prediction model, DDA maps different sessions to different prediction models.（“Nearest Neighbor” prediction model、“Global” prediction model、…） Algorithm Overall workflow First, DDA learns a prediction model $M_s^*$ based on history data. Second, DDA estimates s’s throughput by the median throughput of sessions Learning of prediction model First, DDA learns a prediction model $M_s^*$ based on history data from a pool of all possible prediction models(这很大程度取决于你的model pool的选择) DDA takes a data-driven approach and finds the best prediction model over a set of history sessions Est(s) Improvement of Bitrate Selection Improving QoE via Exploration and Exploitation at Scale data-driven QoE optimization should instead be cast as a real-time exploration and exploitation (E2) process rather than as a prediction problem. Pytheas Using an end-to-end implementation and a proof-of-concept deployment in CloudLab Limitations of Predictive Approaches Limitation 1: Prediction Bias Limitation 2: Slow Reaction Casting QoE Optimization as a Exploration-Exploitation Process Note that the reward functions could change over time, and thus this is a continuous process rather than a one-time shot. Challenges of E2 in the Networking Context need fresh measurements of all sessions, but getting such a fresh and global view is challenging Traditional E2 techniques also make strong assumptions about the context that affects the reward of a decisions, but they may not hold in network settings. Overview of Pytheas if two sessions share the context that determines their E2 decisions, they will be likely to match on some network-specific features. we group together sessions with similar context by network locality and other key features (such as device and location), and use one E2 process for each group. System overview Each session group is managed by one per-group E2 process run by one frontend cluster When a session comes in, it sends a request for its control decisions, which includes its features, to the Pytheas system The request will be received by a frontend cluster, which maps the session to a group based on its features, then gets the most up-to-date decision from the local per-group E2 process, and returns the decision to the session Each session measures its QoE and reports it to the same frontend cluster. When this frontend receives the QoE measurement, it again maps the session to a group, and updates the E2 logic of the group with the new measurement. Pytheas Algorithms Session-Grouping Logic sessions in the same group share not only the best decision, but also the factors that determine the best decisions. Given a session set, the session-grouping logic should output any non-overlapping partition of sessions Per-Group E2 Logic UCB (Upper Confidence Bound) algorithms [48] are a family of algorithms to solve the multi-armed bandits problem First, each frontend cluster runs an active E2 algorithm rather than merely executing the (stale) prediction decisions as in prior work. Second, the frontend clusters now run per-group logic, not per-session logic. Frontends and Backends Frontends: Pick one cluster as the leader cluster of this group and let it run the E2 logic of the group based on the measurements. Oher clusters, called proxy clusters of the group, receive decisions from the leader cluster. Proxy clustersforward QoE measurements to the leader cluster Backends: Updating Session Groups the backend runs the session-grouping logic to decide which group each session belongs to, and outputs a session-to-group table we select the frontend cluster that receives most sessions in the group as the leaderExpressions Expressions it has become of paramount importance that … Despite the intense research towards better Internet QoE … We elaborate on these quality problems in Chapter 2. other details are omitted for clarity. leverage 利用 well-provisioned 精心调配的 our ultimate objective is to improve As we will see, our solution strikes a better balance between the visibility to user-perceived QoE and the visibility to network conditions through taking a more data-driven approach to endpoint solutions dissertation 专题 The main contribution of this dissertation is … n essence, … 本质上 a key domain-specific insight that enables us to address both challenges in practice\ As a concrete example, let us consider]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>QoE</tag>
        <tag>DDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VIA ：Improving Internet Telephony Call Quality Using Predictive Relay Selection]]></title>
    <url>%2F2019%2F05%2F14%2FVIA-%EF%BC%9AImproving-Internet-Telephony-Call-Quality-Using-Predictive-Relay-Selection%2F</url>
    <content type="text"><![CDATA[Introduction ScenarioThe use of Internet for voice call, i.e. Skype, WhatsApp, WeChat, FaceTime Introduction VIA uses an approach called prediction-guided explorationto decide which calls to relay and to pick the relay(s). 是否中继以及选择哪个中继 It makes these decisions with performance information from call history, which tends to be limited and highly skewed. 利用history信息，但又说history信息非常有限且偏颇 even though available performance information from call history may not suffice to accurately predict the best relay for each call, it can nevertheless help identify a small subset of relay choices that contains the best relay.根据 history信息给出一个包含最优解的集合。 we use performance information from call history to filter out all but the most promising (top-k) relaying alternatives, from which, we then employ an online exploration-exploitation strategy to identify the optimal relay path, while staying within the relaying budget. Top-k choices，然后寻找optimal relay path, 好的想法。top-k中的k是一个可选参数，当k=1时就是直接给选择了，和我们平时理解采用的学习方法一致，但之前提到根据观察这并不一定是最优解；当k大时，趋于问题的规模又会类似搜索的方法，维度带来的复杂度成为问题。这两种思想的trade off。 Contributions 分析了net performance对通话质量的影响 量化了a managed overlay network对于通话质量的改进 提出了relay selection algorithm， 性能是close to optimal VoIP Performance in the Wild Dataset dataset from Skype, consist of a sampled set of 430 million audio calls 好大的数据集，羡慕 数据集中包含路由使用默认路径(e.g., BGP-derived)和使用数据中心的managed relay nodes这两种 Each call is associated with three metrics of network performance: (i) round-trip time (RTT), (ii) loss rate, and (iii) jitter。这里没有带宽，作者给出的解释是VoIP是低数据率业务。 对call quality离散的标注，from 1 (worst) to 5 (best). 1 or 2 被认为是 “poor quality”，用来计算”Poor Call Rate (PCR)” 除了PCR，[17] 也提供了一种分析audio call quality的工具， Mean Opinion Score (MOS) 分析call quality 与 Network performance use-perceived quality对network performance (RTT, loss rate and jitter)敏感。 对数据分析，给出了统计的over 15%的PCR案例各个netwoek performance 参数的门限值。( RTT over 320ms, or loss over 1.2%, or jitter more than 12ms ). 给出了poor network rate的定义： performance on the metric is worse than the chosen thresholds: RTT 320ms, loss rate 1.2%, jitter 12ms. One of our goals is to reduce PNR of each individual metric Call with poor networks有什么共同的特点？spatial and temporal Spatial patterns: International 比Domestic 的PNR更高，Inter-AS比Intra-AS的PNR更高。This means that localized solutions that fix a few bad ASes or AS pairs, e.g., informing the AS administrators or the clients directly regarding their ISPs, are not sufficient. This suggests that poor network performance is quite widespread, highlightingthe suitability of a globally deployed overlay network thatprovides high performance inter-connection between overlay nodes. Temporal patterns: we need to dynamically decide if a call should use default Internet routing or be relayed. VIA VIA Architecture consists of relay nodes placed at globally distributed datacenters, such as those run by Amazon, Google, and Microsoft 在caller和callee存在一个controller, 由它来根据historical calls和policy constraints来决定是否中继，如何中继。 历史测量数据由skype client周期性地提供给controller。controller不需要主动monitor relay nodes，Skype clients会提供end-to-end measurements。 relay options: the default (direct) path, a bouncing relay path (one-hop) , or a transit relay path (pair) Need for dynamic relay selection: The optimal relaying option for 30% of AS pairs lasts for less than 2 days, and only 20% of AS pairs have the same optimal relay option for more than 20 days. 在通信研究中也是 The relay selection should be done dynamically, rather than statically. VIA Relay Selection We describe two classes of strawman appro aches— purely predictive and exploration-based — and highlight limitations of both classes. We then present the core intuition behind our relay selection algorithm, called predictionguided exploration and then describe the solution.和之前在Introduction中提到的一样，基于预测一次到位和基于探索的方法结合。 Our goal is to assign each call to a particular relaying option. $\mathop{\arg\min}\limits_{Assign\in R^C} \sum\limits_{c\in C}Q(c, Assign(c))$, 全局优化，不是针对单个call优化。 Strawman approacher Exploration-based: for every AS-pair and every possible relaying option r, we will explicitly use some of the calls to explore the option and measure the performance, Q(c, r). Prediction-based: we can use suitable prediction algorithms to predict theperformance Q(c, r) for every combination, and select the option that has the best predicted performance. 这两个方法预测Q(c,r)竟然都不好， two key reasons: there is a substantial difference in the number of call samples available across different source-destination pairs, both for the direct path and for the various relayed paths. To estimate Q(c, r), we need a significant number of samples before the empirically observed. 没有见过的source-destination配对怎么处理 Network tomography can help estimate the performance of each network segment. Then, by stitching together the estimates for the individual segments, we can estimate the performance of a path not seen before Prediction: $Pred_{mean}(s,d,r)$ $Pred_{sem}(s,d,r)$ standard error of mean 95% confidence bounds $Pred_{lower}(s,d,r)=Pred_{mean}(s,d,r)-1.96Pred_{sem}(s,d,r)$ $Pred_{upper}(s,d,r)=Pred_{mean}(s,d,r)+1.96Pred_{sem}(s,d,r)$ Pruning to get top-k choices Instead of using a fixed value of k, VIA dynamically decides k based on the lower and higher confidence bounds for each relay r on the particular source-destination pair s and d. top-k中k的中继的上界比不在top-k中的下界还要小 Exploration-exploitation step assigns a fraction of calls to explore different relay options ($\epsilon$-greedy) and the rest to exploit the best decision UCB1 algorithm: 数据variance大时直接Normalization会有问题，相同的case会有不同的decision.UB1 Algorithm用来处理exploration. 不太理解怎么得到$C_r\leftarrow{c^\prime|Assign(c^\prime)=r}$：是实时获取当前使用中继r的$c\prime$吗？ 引入了general exploration来处理dynamic环境 Budgeted relaying 使用中继的calls所占比例要有限制，e.g., 30% It decides to relay a call only if the benefit of relaying is sufficiently high. It decides to relay a call only if the expected benefit is above the Bth percentile benefit. Evaluation Evaluation The calls are replayed in the same chronological as in the trace. the relaying options considered for a call are only those with at least 10 call samples on at least 5 relay options。为了使中继的选择更优信服力 Benefits of prediction-guided exploration instead of picking a fixed number top candidates, VIA pick top candidates by taking variance of prediction into account Practical relaying factors Relaying budget: we define budget as the maximum fraction of calls being relayed. Budget-aware VIA relays a call only when the benefit is larger than a threshold. 没看懂这里Oracle是那个参数如何控制budget的。 Relaying decision granularities:First, making decision at granularities coarser than a per AS pair results in a smaller reduction in PNR; Second, making decisions on finer granularities does not help much, though for a different reason.所以最好的空间粒度是AS对 Relay usage: Removing 50% of the (least used) relays causes little drop in VIA’s gains. Real-world controlled deployment We implemented and deployed a prototype containing the relevant components of VIA at a small scale using modified Skype clients and using Skype’s production relays. The central controller of our prototype (Figure 7), deployed on the public Microsoft Azure cloud, aggregated performance measurements from instrumented Skype clients and implemented the relay selection algorithm. 这也太酷了，真的部署了还对Skype client进行了modification. Expressions Expressions To bridge this gap, we analyze … largely ineffective pragmatic practical 务实的，实用的 spanning 135 million users across 126 countries But contrary to our intuition envision 预想 whose overhead can be prohibitive at large scale overhead 在大规模问题中的痛点 close-to-optimal For each network metric, we bin calls based on theirnetwork performance and show the PCR of the calls withineach bin. Strawman approaches : The strawman is not expected to be the last word; it is refined until a final model or document is obtained that resolves all issues concerning the scope and nature of the project. 中间过渡的方法 Confusion ASes是啥？ area states? Trace-driven analysis shows that an oracle-based overlay can potentially improve up to 53% of calls whose quality is impacted by poor network performance. oracle performance是怎么来的,oracle是说搜索遍历下的最优情况吗？]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>VoIP</tag>
        <tag>Relay Selection</tag>
        <tag>Data-Driven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[final test]]></title>
    <url>%2F2019%2F05%2F13%2Ffinal-test%2F</url>
    <content type="text"><![CDATA[#流程123456789git pullhexo new post &quot;article&quot;git add .git commit -m &quot;add a post&quot;git pushhexo d -ghexo s 测试1startdocker -u &quot;-it -e PYTHONPATH=/ghome/mengjw/perl5/LearningToPaint/lib&quot; -c /bin/bash bit:5000/cxs-py36-tf112-torch041 PBS作业123456789101112131415#PBS -N LearningToPaint#PBS -o /ghome/mengjw/perl5/LearningToPaint/LearningToPaint.out#PBS -e /ghome/mengjw/perl5/LearningToPaint/LearningToPaint.err#PBS -l nodes=1:gpus=1:S#PBS -r ycd $PBS_O_WORKDIRecho Time is `date`echo Directory is $PWDecho This job runs on following nodes:echo -n &quot;Node:&quot;cat $PBS_NODEFILEecho -n &quot;Gpus:&quot;cat $PBS_GPUFILEecho &quot;CUDA_VISIBLE_DEVICES:&quot;$CUDA_VISIBLE_DEVICESstartdocker -u &quot;-e PYTHONPATH=/ghome/mengjw/perl5/LearningToPaint/lib&quot; -c &quot;python3 /ghome/mengjw/perl5/LearningToPaint/baseline/train_renderer.py&quot; bit:5000/cxs-py36-tf112-torch041 提交和查看状态1234qsub perl5/PBS_FILES/LearningToPaint.pbs sudo chk_res G105 mengjwchk_gpuused G105qstat -n|grep mengjw]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>命令行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F13%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
